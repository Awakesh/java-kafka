server.port=4040
#spring.kafka.bootstrap-servers=localhost:9092

kafka.consumer.group.prefix=${ds_kafka_consumer_group_prefix}
kafka.consumer.concurrency=${ds_kafka_consumer_concurrency}
spring.kafka.properties.consumer.enable-auto-commit=true

# TODO: Fetch value from configMap
custom.kafka.listeners.listener-1.topic=default-destination_sender-topic
custom.kafka.listeners.listener-1.listener-class=KafkaCustomMessageListener

# Required connection configs for Kafka producer, consumer, and admin
spring.kafka.properties.bootstrap.servers=${bootstrap_servers}
spring.kafka.properties.security.protocol=SASL_SSL
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule   required username='${required_username}'   password="${password}";
spring.kafka.properties.sasl.mechanism=PLAIN
# Required for correctness in Apache Kafka clients prior to 2.6
spring.kafka.properties.client.dns.lookup=use_all_dns_ips

# Best practice for higher availability in Apache Kafka clients prior to 3.0
spring.kafka.properties.session.timeout.ms=45000

# Best practice for Kafka producer to prevent data loss
spring.kafka.properties.acks=all

# Required connection configs for Confluent Cloud Schema Registry
spring.kafka.properties.schema.registry.url=${schema_registry_url}
spring.kafka.properties.basic.auth.credentials.source=USER_INFO
basic.auth.user.info=${basic_auth_user_info}
thread.pool.size=${ds_thread_pool_size}
thread.pool.max.size=${ds_thread_pool_max_size}
thread.queue.capacity=${ds_thread_queue_capacity}
thread.pool.name=ConsumerThread
rest.client.thread.pool.size=${ds_rest_thread_pool_size}
rest.client.thread.pool.max.size=${ds_rest_thread_pool_max_size}
rest.client.thread.queue.capacity=${ds_rest_thread_queue_capacity}
rest.client.thread.pool.name=RestClientThread

# logging.level.root=OFF
# logging.level.co.lemnisk=TRACE

spring.profiles.active=common
spring.datasource.url=${db_url}
spring.datasource.username=${db_username}
spring.datasource.password=${db_password}
spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5InnoDBDialect
spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl


logging.level.com.zaxxer.hikari.HikariConfig=${ds_hikari_debug_config}
spring.datasource.hikari.minimumIdle=${ds_hikari_minimum_idle}
spring.datasource.hikari.connectionTimeout=${ds_hikari_connection_timeout}
spring.datasource.hikari.idleTimeout=${ds_hikari_idle_timeout}
spring.datasource.hikari.maxLifetime=${ds_hikari_maxlifetime}


# S3 upload properties
s3Upload.lemnisk.enable=${ds_s3_upload_lemnisk_enable}
s3Upload.client.enable=${ds_s3_upload_client_enable}
s3Upload.lemnisk.bucket-name=${ds_s3_upload_lemnisk_bucket_name}